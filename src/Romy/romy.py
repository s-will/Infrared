#!/usr/bin/env python3

# -----------------------------
# (C) Sebastian Will, 2018
#
# This file is part of the InfraRed source code.
#
# InfraRed provides a generic framework for tree decomposition-based
# Boltzmann sampling over constraint networks
#

###############################
## @file
## Romy based on InfraRed
##
## Samples over alignments

import random
import argparse
import itertools
import os

import infrared as ir
import treedecomp
import rna_support

import numpy as np

import clustering as cl
from Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor, DistanceMatrix
from Bio import AlignIO, Phylo
import sys

import RNA

def hamming_distance(xs,ys):
    """
    @brief pairwise generic hamming distance
    @param xs iteratable 1
    @param ys iteratable 2
    @return hamming distance between xs and ys
    """
    return sum(map(lambda x:x[0]!=x[1], zip(xs,ys)))

## @brief InfraRed function to control hamming distance
class HammingDistance(ir.Function):
    def __init__(self, i, j, weight):
        super().__init__([i, j])
        self.i = i
        self.j = j
        self.weight = weight
    def __call__(self, a): #overrides
        a = a.values()
        if (a[self.i]==a[self.j]):
            return self.weight
        else:
            return 1

## A gap pattern (of an alignment string)
class GapPattern:
    ## @brief construct from alignment string or 'raw' gap_pattern
    def __init__(self, sequence):
        if type(sequence) is str:
            self._gap_pattern = [ sequence[i]=='-' for i in range(len(sequence)) ]
        else:
            self._gap_pattern = sequence

        self._ptc = list()
        self._ctp = list()
        p=0
        for c,x in enumerate(self._gap_pattern):
            if not x:
                self._ctp.append(p)
                self._ptc.append(c)
                p += 1
            else:
                self._ctp.append(None)
        
        self._seqlen = len(self._gap_pattern) - sum(self._gap_pattern)

    def __getitem__(self, i):
        return self._gap_pattern[i]

    def is_gap(self, i):
        return self._gap_pattern[i]

    def __len__(self):
        return len(self._gap_pattern)

    def seqlen(self):
        return self._seqlen

    ## @brief sequence position to column
    def pos_to_col(self, i):
        return self._ptc[i]

    ## @brief column to sequence position
    def col_to_pos(self, i):
        c = self._ctp[i]
        assert(c is not None)
        return c

    ## @brief alignment string from ungapped sequence
    def sequence_to_alistr(self, sequence):
        s = ['-'] * len( self )
        for i,x in enumerate(sequence):
            s[self._ptc[i]]=x
        return "".join(s)

    def __str__(self):
        def f(x):
            return {True:'-',False:'.'}[x]
        return "".join( [ f(x) for x in self._gap_pattern ] )

    def __repr__(self):
        return str(self)

## A sample generated by class RomySampler
class RomySample:
    def __init__(self, values, alisize, gap_patterns):
        self._values = values
        self._alisize = alisize
        self._gap_patterns = gap_patterns
        self._seqnum = len(self._gap_patterns)
        assert(self._seqnum != 0)
        self._sequences = self._values_to_sequences(self._values)
        self._sequences = [ gp.sequence_to_alistr(seq) for seq,gp in zip(self._sequences,self._gap_patterns) ]

    def _values_to_sequences(self,vals):
        seqs = []
        offset=0
        for i in range(self._seqnum):
            seqlen = self._gap_patterns[i].seqlen()
            seq = rna_support.values_to_sequence(vals[offset:offset+seqlen])
            seqs.append(seq)
            offset = offset + seqlen
        return seqs

    def sequences(self):
        return self._sequences

    def alignment(self):
        return self._sequences[:self._alisize]

    def __getitem__(self,i):
        return self._sequences[i]

## @brief GC content feature
class GCFeature(ir.Feature):
    def __init__(self, weight, target, tolerance):
        super().__init__( "GC", weight, target, tolerance )
    def eval(self, sample):
        return rna_support.GC_content( "".join(sample.sequences()) ) * 100

## @brief Turner energy feature
class EnergyFeature(ir.Feature):
    def __init__(self, index, structure, weight, target, tolerance):
        super().__init__( ("E",index), weight, target, tolerance )
        self.structure = structure
        self.index = index

    def eval(self, sample):
        sequence = sample[self.index].replace("-","")
        #print("EnergyFeature::eval",sequence,self.structure)
        fc = RNA.fold_compound(sequence)
        return fc.eval_structure(self.structure)

    def idstring(self):
        return "".join(map(str,self.identifier))

## @brief sequence distance feature
class DistanceFeature(ir.Feature):
    def __init__(self, phylotree_edge, weight, target, tolerance):
        i = phylotree_edge[0]
        j = phylotree_edge[1]

        super().__init__( ("D", i, j), weight, target, tolerance )

        self.i = i
        self.j = j

    def eval(self, sample):
        return hamming_distance( sample[self.i], sample[self.j] )

    def idstring(self):
        return "_".join(map(str,self.identifier))

## @brief a RNA secondary structure
class RnaStructure:
    ## @brief init from dot bracket string
    def __init__(self, dbstring):
        self._dbstring = dbstring
        self._pairings = rna_support.parseRNAStructure(dbstring)
        self._basepairs = rna_support.parseRNAStructureBps(dbstring)

    def __len__(self):
        return len(self._dbstring)

    def dot_bracket(self):
        return self._dbstring

    def pair_array(self):
        return self._pairings

    def basepairs(self):
        return self._basepairs

## @brief Construct and hold constraint network for mult-target design
## based in the base pair energy model
class RomyConstraintNetworkFactory:
    ## @brief Constructor
    def __init__( self ):
        pass

    ## @brief create constraint network
    ## @gap_patterns list of the gap patterns of all sequences in the tree
    ## @param alnsize number of sequences in the alignment (w/o sequences at inner nodes)
    ## @param seqnum number of all sequences
    ## @param phylotree list of edges of the phylogenetic tree
    ## @param structures list of target structures of all sequences
    ## @param features the features containing weights of energies and GC control
    def create( self, gap_patterns, alnsize, seqnum, phylotree, structures, features ):
        self.gap_patterns = gap_patterns    
        self.alnsize = alnsize
        self.seqnum = seqnum

        # construct helper array for variable index computation
        self.idx_offsets = [0] 
        self.idx_offsets.extend( itertools.accumulate( [ self.gap_patterns[i].seqlen() for i in range(self.seqnum) ] ) ) 

        self.alnlen = len(gap_patterns[0]) # number of columns in the alignment
        self.phylotree = phylotree
        self.structures = [ RnaStructure(s) for s in structures ]
        self.features = features

        self.generate_constraints_and_functions()

        cn = ir.ConstraintNetwork( varnum = self.alnlen * self.seqnum, domains = 4,
                constraints = self.bp_constraints,
                functions = self.gc_functions + self.energy_functions + self.distance_functions )

        return cn


    ## @brief Get variable id by sequence position
    ## @param seq_id sequence id
    ## @param pos sequence position
    def vid_pos(self, seq_id, pos):
        assert( seq_id < self.seqnum )
        assert( 0 <= pos )
        assert( pos < self.idx_offsets[seq_id+1] )
        return self.idx_offsets[seq_id] + pos 
    
    ## @brief Get variable id by alignment column
    ## @param seq_id sequence id
    ## @param col alignment column 
    def vid_col(self, seq_id, col):
        assert( seq_id < self.seqnum )
        assert( 0 <= col )
        assert( col < self.alnlen )
        return self.idx_offsets[seq_id] + self.gap_patterns[seq_id].col_to_pos(col) 

    ## @brief Generate constraint network constraints and functions
    def generate_constraints_and_functions(self):

        # determine constraints due to consensus structure
        self.bp_constraints = list()
        for i in range(self.alnsize):
            self.bp_constraints.extend( [ rna_support.ComplConstraint(self.vid_pos(i,p), self.vid_pos(i,q))
                                          for p,q in self.structures[i].basepairs() ] )

        # set up dependencies due to evolutionary distance
        self.distance_functions = [ HammingDistance(self.vid_col(i,k), self.vid_col(j,k),
                                                    self.features[("D", i, j)].weight )
                                    for k in range(self.alnlen) for (i,j) in self.phylotree
                                    if not ( self.gap_patterns[i].is_gap(k) or self.gap_patterns[j].is_gap(k) )
                                    ]

        # determine energy functions due to consensus structure
        self.energy_functions = list()
        for i in range(self.alnsize): 
            self.energy_functions.extend( [ rna_support.BPEnergy(self.vid_pos(i,p), self.vid_pos(i,q),
                                               not (p-1,q+1) in self.structures[i].basepairs(),
                                               self.features[("E",i)].weight )
                                            for p,q in self.structures[i].basepairs() ] )

        # GC content control
        self.gc_functions = [ rna_support.GCControl( self.vid_col(i,j), self.features["GC"].weight )
                              for i in range(self.seqnum) for j in range(self.alnlen)
                              if not self.gap_patterns[i].is_gap(j) ]


class RomySampler(ir.MultiDimensionalBoltzmannSampler):
    def __init__( self, gap_patterns, alnsize, phylotree, structures, features,
                  *, td_factory, cn_factory ):
        super().__init__( features )

        self.gap_patterns = gap_patterns

        self.alnsize = alnsize
        self.seqnum = len(gap_patterns)
        self.phylotree = phylotree
        self.structures = structures
        self.features = features

        self.td_factory = td_factory
        self.cn_factory = cn_factory

        self.setup_engine()

    ## @brief Generate constraint network
    ## @param features dictionary of features
    ## @return constraint network
    def gen_constraint_network(self):
        return self.cn_factory.create(self.gap_patterns, self.alnsize, self.seqnum, self.phylotree,
                                        self.structures, self.features)

    ## @brief Generate tree decomposition
    ## @param cn constraint network
    ## @return tree decomposition
    def gen_tree_decomposition(self, cn):
        ## make tree decomposition
        return td_factory.create( cn )

    def gen_cluster_tree( self ):
        return ir.ClusterTree( self.cn, td = self.td )

    ## @brief Calculate sample
    ## @return sampled RNA sequence
    def sample(self):
        return RomySample(super().sample().values(), self.alnsize, self.gap_patterns)

##Additional useful functions
def all_edges(tree,n):
    phylo_v = []
    phylo = []
    seqnum = n
    for clade in tree.find_clades(order='level'):
        for child in clade:
            if child.name[:5]=="Inner":
                if child.name=="Inner": #Case of only one Inner node
                    child_name=n
                    seqnum +=1
                else:
                    i = int(child.name.split('r')[1])+n-1
                    if i+1>seqnum:
                        seqnum=i+1
                    child_name = i
            else: child_name=int(child.name)

            if clade.name[:5]=="Inner":
                if clade.name=="Inner": #Case of only one Inner node
                    clade_name=n
                    seqnum +=1
                else:
                    i = int(clade.name.split('r')[1])+n-1
                    if i+1>seqnum:
                        seqnum=i+1
                    clade_name = i
            else: clade_name=int(clade.name)

            phylo_v.append((clade_name,child_name,child.branch_length))
            phylo.append((clade_name,child_name))


    return phylo_v,phylo,seqnum

def all_edges_nhx(tree,n):
    phylo_v = []
    phylo = []
    index_in, index_out = n,0
    for clade in tree.find_clades(order='level'):
        for child in clade:

            if clade.comment == None:
                clade_name = index_in
                index_in += 1
            else:
                clade_name = index_out
                index_out +=1

            if child.comment == None:
                child_name = index_in
                index_in += 1
            else:
                child_name = index_out
                index_out +=1

            phylo_v.append((clade_name,child_name,child.branch_length))
            phylo.append((clade_name,child_name))

    return phylo_v,phylo,index_in


def gap_positions(sequence):
    """
    @return gap positions of a sequence
    """
    return [ i for i,x in enumerate(sequence) if x=='-' ]

def remove_pos_sequence(sequence, positions):
    """
    @brief remove a set of positions from a sequence
    @param sequence
    @returns sequence without positions
    """
    if type(positions) is not set:
        positions = set(positions)
    return "".join( x for i,x in enumerate(sequence) if i not in positions )

def remove_pos_structure(structure, positions, *, pairings=None):
    """
    @brief remove positions from an RNA structure
    @note takes care of base pair ends
    """

    if type(positions) is not set:
        positions = set(positions)

    if pairings == None:
        pairings = rna_support.parseRNAStructure(structure)

    structure = list(structure)
    for i in positions:
        j = pairings[i]
        if j != -1:
            structure[j] = '.'
    return remove_pos_sequence(structure, positions)

def analyze_alignment(sequences,consensus_structure):
    average_gc=0
    structures=[]
    energies=[]

    gps = [ set(gap_positions(s)) for s in sequences ]
    sequences_wo_gaps = [ remove_pos_sequence(s,gps[i]) for i,s in enumerate(sequences) ]
    consensus_pairings = rna_support.parseRNAStructure(consensus_structure)

    for i,seq in enumerate( sequences_wo_gaps ):
        fc = RNA.fold_compound(seq)

        projected_cs  = remove_pos_structure(consensus_structure, gps[i], pairings=consensus_pairings)
        fc.hc_add_from_db(projected_cs)

        mfe = fc.mfe()
    
        structures.append(mfe[0])
        energies.append(mfe[1])

    gc_content = rna_support.GC_content("".join(sequences_wo_gaps)) * 100

    return gc_content,structures,energies

def get_alignment_features(args):
    #aln=AlignIO.read(args.infile,'stockholm')
    sequences= list(RNA.file_msa_read(args.infile)[2])
    msa_size= len(sequences)
    if args.newick!=None:
        tree=Phylo.read(args.newick,'newick')
        phylo_v,phylotree,seqnum = all_edges_nhx(tree,msa_size)
    else:
        ds_mat = [[0 for i in range(i+1)] for i in range(msa_size)]
        for i in range(msa_size):
            for j in range(i):
                ds_mat[i][j] = hamming_distance(sequences[i],sequences[j])

        distance_matrix = DistanceMatrix([str(i) for i in range(msa_size)],ds_mat)

        constructor = DistanceTreeConstructor()
        tree=constructor.nj(distance_matrix)
        phylo_v,phylotree,seqnum = all_edges(tree,msa_size)

    #GC content and energy
    if args.struct == None:
        consensus_structure = RNA.alifold(sequences)[0]
    else:
        consensus_structure = args.struct

    gc,structures,energies=analyze_alignment(sequences,consensus_structure)
    return {"Sequences": sequences, "Consensus":consensus_structure,"GC":gc,"Structures":structures,"Energies":energies,"Tree":tree,"Phylotree":phylotree,"Phylo_v":phylo_v,"Seqnum":seqnum,"Size":msa_size}


"""
A quite specialized tree class

Supports traversal based on a list of edges
@note makes quite a few assumptions on edges and nodes (@see infer_inner_gap_patterns)!
"""
class Tree():
    def __init__(self,edges):
        self.nodes = set()
        for (i,j) in edges:
            self.nodes.add(i)
            self.nodes.add(j)

        self.adjacency = dict()
        for (i,j) in edges:
            if i not in self.adjacency:
                 self.adjacency[i]=list()
            if j not in self.adjacency:
                self.adjacency[j]=list()
            self.adjacency[i].append(j)
            self.adjacency[j].append(i)

        self.parent = dict()
        self.children = dict()

        self.root = max(self.nodes)
        self._init_parents_and_children(self.root)

    def _init_parents_and_children(self,i,parent=None):
        self.parent[i] = parent
        self.children[i] = []
        for j in self.adjacency[i]:
            if j!=parent:
                self._init_parents_and_children(j,i)
                self.children[i].append(j)

def infer_inner_gap_patterns( sequences, tree_edges ):
    """
    @brief Infer the gap patterns at the inner leaves of the tree
    @param sequences sequences/alignment strings of the alignment (including gaps)
    @param tree as list of edges
    @returns list of all gap patterns

    @pre the indices of sequences and node indices of the leave nodes in tree correspond;
    in tree the leaves must have the indices in range(number of leaves), inner nodes have integer indices
    in range(number of leaves, number of nodes); all sequences have the same length
    """

    leave_gap_patterns = [ GapPattern(x) for x in sequences ]
    leave_num = len(leave_gap_patterns)

    if leave_num==0:
        return []

    seqlen = len(sequences[0])

    tree = Tree(tree_edges)

    ## We run a fitch maximum parsimony algo with trace back, separately on each alignment column
    ##

    # we follow this schema:

    # foreach alignment column
    #   ## fitch_fwd
    #   traverse nodes in post order, at each node
    #      determine and store max parsimonius scores for each node type
    #
    #   determine best node type
    #
    #   ## fitch_tb
    #   traverse pre-order, at each node
    #      choose types for children that yield maximum score

    values = [False,True]

    cost_tab = dict()

    def fitch_fwd( node, col ):
        ncost_tab = dict()
        if tree.children[node] == []:
            # init the table
            g = leave_gap_patterns[node][col]
            ncost_tab[g] = 0
            ncost_tab[not g] = 10**9 # hackish for 'infinite cost'
        else:
            # run algo on kids and infer the table
            for child in tree.children[node]:
                fitch_fwd(child, col)

            for v in values:
                ncost_tab[v] = sum( min( cost_tab[child][v], cost_tab[child][not v] + 1 ) for child in tree.children[node] )

        cost_tab[node] = ncost_tab

    tb_values = dict()
    def fitch_tb( node, val ):
        tb_values[node]=val

        # pick optimal values for children
        children = tree.children[node]

        if children == []:
            return

        best_cost = 10**9
        best_values = None
        for children_values in itertools.product( values, repeat=len(children) ):
            cost = sum( cost_tab[children[cidx]][children_values[cidx]] + (children_values[cidx]!=val) for cidx in range(len(children)) )
            if cost < best_cost:
                best_cost = cost
                best_values = children_values

        for cidx in range(len(children)):
            fitch_tb( children[cidx], best_values[cidx] )

    gap_patterns = [ [] for node in tree.nodes ]

    for col in range(seqlen):
        fitch_fwd( tree.root, col )

        best_cost,best_val = min( (cost_tab[tree.root][val],val) for val in values )

        fitch_tb( tree.root, best_val )

        for node in tree.nodes:
            gap_patterns[node].append(tb_values[node])

    return [ GapPattern(x) for x in gap_patterns ]

def subtract_gap_distances( tree, gps ):
    """
    @brief subtract hamming distances between gap patterns for each branch of a tree

    Corrects the tree lengths to reflect hamming distances between non-gap positions

    @param tree tree edges with lengths (list of triples x,y,l)
    @param gps gap patterns of the nodes
    """
    return [ (x,y,l - hamming_distance(gps[x],gps[y])) for (x,y,l) in tree ]

## @brief command line tool definition
## @param args command line arguments
def main(args):

    if args.listtds:
        print("Avalaible tree decomposition methods", treedecomp.get_td_factory_descriptors())
        return

    ## init seed
    if args.seed == None:
        ir.seed(random.randint(0,2**31))
    else:
        ir.seed(args.seed)

    # set base pair energies
    rna_support.set_bpenergy_table()

    #Get instance from alignment
    msa_features = get_alignment_features(args)

    sequences = msa_features["Sequences"]
    structures = msa_features["Structures"]
    energies = msa_features["Energies"]

    seqnum=msa_features["Seqnum"]
    alnsize=msa_features["Size"]
    phylotree=msa_features["Phylotree"]
    phylotree_v=msa_features["Phylo_v"]

    # infer gap patterns at inner nodes
    gap_patterns = infer_inner_gap_patterns(sequences, phylotree)
    if args.verbose:
        print("Gap patterns",gap_patterns)

    ## whether we need something like the following correction, depends on our exact handling
    # of distances in the distance feature; currently, we don't want to
    # change distances (but keep the code for later)
    #
    # update the branch lengths in the phylo tree by subtracting gap-caused distances
    #corrected_phylotree_v = subtract_gap_distances( phylotree_v, gap_patterns )
    #if args.verbose:
    #    print(phylotree_v,'--->',corrected_phylotree_v)
    corrected_phylotree_v = phylotree_v

    ## GC feature
    features = [ GCFeature(args.gc_weight,msa_features["GC"],args.gc_tolerance) ]

    ## Energy features
    features.extend( [ EnergyFeature( i, structures[i], args.energy_weight, energies[i], args.energy_tolerance )
                       for i in range( alnsize ) ] )

    ## Distance features
    features.extend( [ DistanceFeature((edge[0],edge[1]), args.distance_weight, edge[2], args.distance_tolerance )
                       for edge in corrected_phylotree_v ] )


    # transform features to the corresponding feature dictionary
    features = { f.identifier:f for f in features }

    # handle args.td
    td_factory = treedecomp.td_factory_from_descriptor(args.td)
    if td_factory is None:
        sys.stderr.write("[ERROR] Invalid tree decomposition method: "+args.td+"\n")
        exit(-1)

    cn_factory = RomyConstraintNetworkFactory()

    sampler = RomySampler( gap_patterns, alnsize, phylotree, structures, features,
                           td_factory = td_factory,
                           cn_factory = cn_factory
                           )

    ## optionally, write tree decomposition
    if args.plot_td:
        sampler.plot_td("treedecomp.dot")

    if args.verbose:
        print("Treewidth:",sampler.treewidth())
        print("The targeted structures are: ",structures)
        print("The targeted average GC content is: ",msa_features["GC"])
        print("The targeted energies are: ",msa_features["Energies"])
    """         print("The phylogenetic tree will be printed in another window, close it tp have the results")
        Phylo.draw(msa_features["Tree"]) """


    fstats = ir.FeatureStatistics()

    ## sample

    if args.mdbs:
        sample_generator = sampler.targeted_samples()
    else:
        sample_generator = sampler.samples()

    sample_count = 0
    alignments=[]
    for sample in sample_generator:
        alignment = sample.alignment()
        alignments.append(alignment)
        print(alignment,end='')
        for i in range(alnsize):
            feat_id, value = fstats.record( sampler.features[("E",i)], sample )
            print(" {}={:3.2f}".format(feat_id, value), end='')

        for (i,j) in sorted(phylotree):
            feat_id, value = fstats.record( sampler.features[("D",i,j)], sample )
            print(" {}={:3.2f}".format(feat_id, value), end='')

        feat_id, value = fstats.record( sampler.features["GC"], sample )
        print(" GC={:3.2f}".format(value),end='')

        print()

        sample_count += 1
        if sample_count >= args.number:
            break

    if args.verbose:
        if not fstats.empty():
            print("----------")
            print("Summary: ",end='')
        fstats.report()

    return alignments,seqnum

if __name__ == "__main__":
    ## command line argument parser
    parser = argparse.ArgumentParser(description='Boltzmann sampling of homologous sequences')

    parser.add_argument('infile',type=str, help="Input Stockholm file of the alignment")

    parser.add_argument('--struct', type=str, default=None, help="Consensus structure for the alignment")

    parser.add_argument('--gc_tolerance', type=float, default=5, help="Target tolerance for the GC content")

    parser.add_argument('--energy_tolerance', type=float, default=5, help="Target tolerance for energies")

    parser.add_argument('--distance_tolerance', type=float, default=1, help="Target tolerance for hamming distances")

    parser.add_argument('--gc_weight', type=float, default=1, help="GC weight")

    parser.add_argument('--energy_weight', type=float, default=1, help="Energy weight")

    parser.add_argument('--distance_weight', type=float, default=1, help="Distance weight")

    parser.add_argument('--td', type=str, default="nx",
                        help="Method for tree decomposition (see --listtds)")
    parser.add_argument('--listtds', action="store_true", help="List available tree decomposition methods")

    parser.add_argument('-n','--number', type=int, default=10, help="Number of samples")

    parser.add_argument('--seed', type=int, default=None,
                        help="Seed infrared's random number generator (def=auto)")


    parser.add_argument("--newick",type=str,default=None,
                        help="Filename of the newick phylogenetic tree to use")

    parser.add_argument('--plot_td', action="store_true",
                        help="Plot tree decomposition")

    parser.add_argument('--mdbs', action="store_true",
                        help="Perform multi-dim Boltzmann sampling to aim at targets")

    parser.add_argument('-v','--verbose', action="store_true", help="Verbose")

    args=parser.parse_args()

    main(args)
